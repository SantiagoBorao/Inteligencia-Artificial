{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este colab forma parte del video de Redes Neuronales Convolucionales del canal de Youtube \"Ringa Tech\"\n",
    "# https://youtu.be/eGDSlW93Bng\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#Descargar set de datos de MNIST (Numeros escritos a mano, etiquetados)\n",
    "datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "\n",
    "#Obtener en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
    "datos_entrenamiento, datos_pruebas = datos['train'], datos['test']\n",
    "\n",
    "#Funcion de normalizacion para los datos (Pasar valor de los pixeles de 0-255 a 0-1)\n",
    "#(Hace que la red aprenda mejor y mas rapido)\n",
    "def normalizar(imagenes, etiquetas):\n",
    "  imagenes = tf.cast(imagenes, tf.float32)\n",
    "  imagenes /= 255 #Aqui se pasa de 0-255 a 0-1\n",
    "  return imagenes, etiquetas\n",
    "\n",
    "#Normalizar los datos de entrenamiento con la funcion que hicimos\n",
    "datos_entrenamiento = datos_entrenamiento.map(normalizar)\n",
    "datos_pruebas = datos_pruebas.map(normalizar)\n",
    "\n",
    "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
    "datos_entrenamiento = datos_entrenamiento.cache()\n",
    "datos_pruebas = datos_pruebas.cache()\n",
    "\n",
    "clases = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo para mostrar imagenes del set, no es necesario ejecutarlo, solo imprime unos numeros :)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
    "  imagen = imagen.numpy().reshape((28,28))\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
    "  plt.xlabel(clases[etiqueta])\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de Flatten la primera capa será de Conv2D y especificaremos 32 núcleos de 3x3. Cada imagen será otra vez de 28x28 y una capa.\n",
    "Creamos también una capa de agrupación máxima 2x2.\n",
    "Repetimos y creamos otra capa de convolución de 64 filtros (núcleos) y agrupación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una capa flatten para que se pueda usar en los vectores de delante.\n",
    "Creamos otra capa densa relu y otra de salida softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el modelo (Ya utiliza capas de convolución y agrupación)\n",
    "#Cuenta con 1 capa de convolución con 32 núcleos y otra con 64. 2 capas de agrupación.\n",
    "#Finalmente una capa densa con 100 neuronas\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), input_shape=(28,28,1), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), #2,2 es el tamano de la matriz\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), #2,2 es el tamano de la matriz\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compilar el modelo\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los numeros de datos de entrenamiento y pruebas (60k y 10k)\n",
    "num_datos_entrenamiento = metadatos.splits[\"train\"].num_examples\n",
    "num_datos_pruebas = metadatos.splits[\"test\"].num_examples\n",
    "\n",
    "#Trabajar por lotes\n",
    "TAMANO_LOTE=32\n",
    "\n",
    "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria\n",
    "#para que el entrenamiento no se aprenda las cosas en orden\n",
    "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_datos_entrenamiento).batch(TAMANO_LOTE)\n",
    "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizar el entrenamiento\n",
    "import math\n",
    "\n",
    "historial = modelo.fit(\n",
    "    datos_entrenamiento,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=math.ceil(num_datos_entrenamiento/TAMANO_LOTE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar el modelo al explorador! (Mas detalle de esto en en mi video de exportacion: https://youtu.be/JpE4bYyRADI )\n",
    "modelo.save('numeros_regular.h5')\n",
    "\n",
    "#Convertirlo a tensorflow.js\n",
    "!pip install tensorflowjs\n",
    "\n",
    "!mkdir carpeta_salida\n",
    "\n",
    "!tensorflowjs_converter --input_format keras numeros_regular.h5 carpeta_salida"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d302c08dd3ab5187b75b99760dbef5a7959d8b81ead926bf375bd77ae90562f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
