{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red no convolucional solo funciona bien si las imágenes que le das son muy parecidas a las que usó en el entrenamiento.\n",
    "Las redes neuronales son muy buenas con las predicciones siempre y cuando definan características.\n",
    "Cuando le damos una imagen, la red trabajará con el valor de cada píxel, por lo que con que lo cambiemos un poco ya se rompe.\n",
    "Una red convolucional trabaja primero con la imagen y luego extrae las características para que no depende solo de la posición o el tamaño de las cosas.\n",
    "Para crear una covolucional, necesitaremos crear dos nuevas capas intermedias, las de convolución y agrupación. Dichas capas extraerán las características relevantes de la imagen para luego trabajar con el resto de capas normales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear una capa de convolución, no indicamos el número de neuronas, como en una capa de neuronas, sino el número de núcleos que se van a usar. (Las matrices esas raras para aplicar filtros)\n",
    "tf.keras.layers.Conv2D(32,(3,3), input_shape=(28, 28, 1))\n",
    "tf.keras.layers.Conv2D(Número de núcleos para procesar la imagen, tamaño de los núcleos (3x3 casillas), tamaño de imagen de entrada(28x28) y el número de canales (no lo tengo claro porqué 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendremos entonces 32 imágenes nuevas con diferentes filtrados. La gracia de todo es que el contenido de los núcleos no se especifican porqué los irá creando la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si usamos fotos a color, dado que están hechas a partir de 3 colores RGB. Se hacen 3 convoluciones por núcleo en vez de 1, por lo que se hacen en este ejemplo 96 convoluciones pero solo 32 resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo esto es para neuronas simples, que solo miran pixel por pixel. Toca pasar a las complejas, que miran un poco más grande. Para ello usamos la capa de agrupación. Esta capa reducirá el tamaño de la imagen y resaltar las características más importantes.\n",
    "Esta vez lo que hará será crear una matriz con los números mayores de los núcleos. Con esto el tamaño se reduce y solo usamos los píxeles más significativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://youtu.be/eGDSlW93Bng\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "#Descargar set de datos de MNIST (Numeros escritos a mano, etiquetados)\n",
    "datos, metadatos = tfds.load('mnist', as_supervised=True, with_info=True)\n",
    "\n",
    "#Obtener en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
    "datos_entrenamiento, datos_pruebas = datos['train'], datos['test']\n",
    "\n",
    "#Funcion de normalizacion para los datos (Pasar valor de los pixeles de 0-255 a 0-1)\n",
    "#(Hace que la red aprenda mejor y mas rapido)\n",
    "def normalizar(imagenes, etiquetas):\n",
    "  imagenes = tf.cast(imagenes, tf.float32)\n",
    "  imagenes /= 255 #Aqui se pasa de 0-255 a 0-1\n",
    "  return imagenes, etiquetas\n",
    "\n",
    "#Normalizar los datos de entrenamiento con la funcion que hicimos\n",
    "datos_entrenamiento = datos_entrenamiento.map(normalizar)\n",
    "datos_pruebas = datos_pruebas.map(normalizar)\n",
    "\n",
    "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
    "datos_entrenamiento = datos_entrenamiento.cache()\n",
    "datos_pruebas = datos_pruebas.cache()\n",
    "\n",
    "clases = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo para mostrar imagenes del set, no es necesario ejecutarlo, solo imprime unos numeros :)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
    "  imagen = imagen.numpy().reshape((28,28))\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
    "  plt.xlabel(clases[etiqueta])\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo con una capa Flatten de 28 x 28 píxeles y 1 solo canal para blanco y negro.\n",
    "Agregamos 2 capas ocultas con 50 neuronas con activación ReLu y una capa de salida con softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear el modelo (Modelo denso, regular, sin redes convolucionales todavia)\n",
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)), #1 = blanco y negro\n",
    "    tf.keras.layers.Dense(units=50, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=50, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compilar el modelo\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las variables para los datos de entrenamiento y de test.\n",
    "Mezclamos y repetimos para que la red no se aprenda el orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los numeros de datos de entrenamiento y pruebas (60k y 10k)\n",
    "num_datos_entrenamiento = metadatos.splits[\"train\"].num_examples\n",
    "num_datos_pruebas = metadatos.splits[\"test\"].num_examples\n",
    "\n",
    "#Trabajar por lotes\n",
    "TAMANO_LOTE=32\n",
    "\n",
    "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria\n",
    "#para que el entrenamiento no se aprenda las cosas en orden\n",
    "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_datos_entrenamiento).batch(TAMANO_LOTE)\n",
    "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un entrenamiento de 60 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizar el entrenamiento\n",
    "import math\n",
    "\n",
    "historial = modelo.fit(\n",
    "    datos_entrenamiento,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=math.ceil(num_datos_entrenamiento/TAMANO_LOTE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar modelo de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exportar el modelo al explorador! (Mas detalle de esto en en mi video de exportacion: https://youtu.be/JpE4bYyRADI )\n",
    "modelo.save('numeros_regular.h5')\n",
    "\n",
    "#Convertirlo a tensorflow.js\n",
    "!pip install tensorflowjs\n",
    "\n",
    "!mkdir carpeta_salida\n",
    "\n",
    "!tensorflowjs_converter --input_format keras numeros_regular.h5 carpeta_salida"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d302c08dd3ab5187b75b99760dbef5a7959d8b81ead926bf375bd77ae90562f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
